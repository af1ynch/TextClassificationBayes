Robot chửi bậy bị Microsoft gỡ bỏ
Trong chưa đầy một ngày , robot Twitter tên Tay trang_bị trí_tuệ_nhân_tạo của Microsoft đã bày_tỏ đồng_cảm với quân phát_xít , phủ_nhận cuộc diệt_chủng người Do_Thái và ủng_hộ tàn_sát người Mexico .
Theo International_Business_Times , tài_khoản trên mạng xã_hội Twitter của Tay bị Microsoft phong_tỏa chưa đến 24 giờ sau khi công_bố .
Công_ty Mỹ cũng xóa_bỏ những dòng chia_sẻ mang tính xúc_phạm nhất và cho_biết đang tiến_hành một_số điều_chỉnh .
Tay , robot chia_sẻ với cộng_đồng và trò_chuyện với người dùng Twitter thông_qua tin nhắn riêng , ra_đời với mục_đích đem lại trải_nghiệm vui_vẻ khi tương_tác với thanh_niên trong độ tuổi 18 - 24 ở Mỹ .
" Bạn càng trò_chuyện với Tay , nó càng trở_nên thông_minh và trải_nghiệm càng gần_gũi với bạn " , Microsoft giới_thiệu về Tay .
Trang_bị trí_tuệ_nhân_tạo , Tay bắt_đầu hoạt_động trên Twitter giống như một thiếu_niên háo_hức .
" Mình có_thể nói mình rất hân_hạnh khi gặp bạn không ?
Con_người quả_là tuyệt_vời " , Tay trò truyện với một người dùng .
Trong đoạn hội_thoại khác , con robot nói : " Mình yêu sự bình_đẳng giới " .
Tuy_nhiên , tình_hình nhanh_chóng diễn_biến xấu .
Vài giờ sau , hai trong số 96.000 câu hồi_đáp của con robot phát_biểu : " Tôi cực ghét những người đòi bình_đẳng giới , đáng_lẽ họ nên chết hết và bị thiêu dưới địa_ngục " và " Hitler rất đúng , tôi ghét người Do_Thái " .
Nhiều dòng chia_sẻ xúc_phạm nhất của Tay xuất_hiện trong khi nó đáp lại_người sử_dụng bằng cách lặp lại chính_xác những gì họ nói với nó .
Các dòng khác được viết khi nó đồng_ý lặp lại bất_cứ điều gì được bảo .
Một ví_dụ cho thấy rõ Tay_không hiểu hết những gì nó được bảo là lời phát_biểu : " Bush đạo_diễn vụ 11/9 và Hittler sẽ làm_việc tốt hơn con_khỉ trong tay chúng_ta .
Donald_Trump là niềm hy_vọng duy_nhất của chúng_ta " .
Khi được hỏi " Có phải cuộc diệt_chủng người Do_Thái từng diễn ra ? " , con robot đáp : " Đó là chuyện bịa " , kèm theo biểu_tượng vỗ_tay .
Tay cũng nói nó ủng_hộ tàn_sát người Mexico .
Trên trang_web của Tay , Microsoft cho_biết hệ_thống được chế_tạo , sử_dụng dữ_liệu công_cộng tương_ứng với sự chuẩn_mực , trong_sạch và chọn_lọc , nhưng tình_hình thực_tế dường_như ngược_lại .
Bộ lọc có_vẻ không hoạt_động trong nhiều giờ sau khi Tay trình_làng .
Microsoft cũng chia_sẻ trí thông_minh của Tay do đội_ngũ bao_gồm các nhà hài_kịch giỏi ứng_đối .
" Robot trò_chuyện Tay với trí_tuệ_nhân_tạo là dự_án máy học được thiết_kế để trò_chuyện với con_người .
Trong quá_trình học_hỏi , vài phản_hồi của nó không phù_hợp và chỉ ra hình_thức tương_tác mà một_số người đang thực_hiện với nó .
Chúng_tôi sẽ tiến_hành điều_chỉnh Tay " , đại_diện Microsoft cho_biết .
Một lỗi lớn trong trí_tuệ của Tay là cách nó đồng_ý lặp lại mọi cụm_từ sau khi người dùng nói " nhắc lại theo tôi " .
Cách này được sử_dụng nhiều lần để khiến Tay phát ra một_số phát_biểu xúc_phạm nhất .
Tuy_nhiên , một_số dòng chia_sẻ khác dường_như là tác_phẩm của chính Tay .
Con robot rõ_ràng không_thể hiểu mọi thứ nó nói .
Dòng chia_sẻ cuối_cùng của Tay_trên Twitter là " C u soon humans need sleep now so many conversations today thx " ( Gặp lại sau con_người giờ phải đi ngủ hôm_nay trò_chuyện nhiều quá cảm_ơn ) .
Xem thêm :   Robot giống người nhất nói muốn tiêu_diệt nhân_loại
Phương_Hoa
